<!doctype html>
<html lang="en" data-bs-theme="light">
  <head>
    <meta charset="utf-8"></meta>
    <meta name="viewport" content="width=device-width, initial-scale=1"></meta>
    <title>logicalmethods.ai &ndash; Valid Inference </title>
    <link rel="icon" type="image/x-icon" href="https://logicalmethods.ai/favicon.ico"></link>
    <link href="https://logicalmethods.ai/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet"></link>
    <link rel="stylesheet" href="https://logicalmethods.ai/icons/font/bootstrap-icons.min.css"></link>
    <link rel="stylesheet" href="https://logicalmethods.ai/css/layout.css"></link>
    <link rel="stylesheet" href="https://logicalmethods.ai/css/syntax_hl.css"></link>
    <link href="https://logicalmethods.ai/css/textbook.css" rel="stylesheet"></link>
    <style>
      
    :root {
      --chapter: "3";
    }

    </style>
    
      <link rel="stylesheet" href="https://logicalmethods.ai/katex/katex.min.css">
<script defer src="https://logicalmethods.ai/katex/katex.min.js"></script>
<script defer src="https://logicalmethods.ai/katex/contrib/auto-render.min.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},     
        {left: '\\[', right: '\\]', display: true},   
        {left: '\\(', right: '\\)', display: false},  
      ],
      throwOnError : false
    });
  });
</script>


    
  </head>
  <body class="bg-black d-flex flex-column m-0 p-0">
    <div class="offcanvas offcanvas-start" tabindex="-1" id="offcanvas-nav" aria-labelledby="offcanvas-navLabel" data-bs-theme="dark" data-bs-backdrop="false">
  <div class="offcanvas-header">
    <div class="h5 offcanvas-title" id="offcanvas-navLabel">
      Browse course
    </div>
    <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close"></button>
  </div>
  
  <div class="offcanvas-body">
    <ul class="navbar-nav">
      
      <li class="nav-item">
        <div class="d-flex flex-row">
          <div class="container">
            <a class="nav-link " href="/about/"><i class="bi-file-person-fill"></i> &nbsp;&nbsp; About</a>
          </div>
      </li>
      
      
      <hr>
      <li class="nav-item">
        <div class="d-flex flex-row">
          <div class="container">
            <a class="nav-link fw-bold active" href="/textbook/"><i class="bi bi-book"></i> &nbsp;&nbsp; Textbook</a>
          </div>
          <button 
            class="btn btn-sm btn-dark" 
            href="/textbook/"
            id="navbarSectiontxt-home" data-bs-toggle="collapse"
            data-bs-target="#collapsetxt-home"  
            aria-expanded="true"
            aria-controls="collapsetxt-home">
            <i class="bi bi-caret-left-fill toggle-icon"></i>
          </button>
        </div>
        <div class="collapse show" id="collapsetxt-home">
          <ul class="list-unstyled ms-3">
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/logic-and-ai/"
              >1. 
                <i class="bi bi-unlock-fill"></i>
                 Logic and AI
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/formal-languages/"
              >2. 
                <i class="bi bi-unlock-fill"></i>
                 Formal languages
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                fw-bold active
                
                "
                href="/textbook/valid-inference/"
              >3. 
                <i class="bi bi-unlock-fill"></i>
                 Valid Inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/boolean/"
              >4. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean algebra
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/sat/"
              >5. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean satisfiability
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/conditionals/"
              >6. 
                <i class="bi bi-unlock-fill"></i>
                 Logical conditionals
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/proofs/"
              >7. 
                <i class="bi bi-unlock-fill"></i>
                 Logical proofs
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/fol/"
              >8. 
                <i class="bi bi-unlock-fill"></i>
                 FOL
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/fol-inference/"
              >9. 
                <i class="bi bi-unlock-fill"></i>
                 FOL Inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/many-valued/"
              >10. 
                <i class="bi bi-unlock-fill"></i>
                 Many-valued logics
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/textbook/probability/"
              >11. 
                <i class="bi bi-unlock-fill"></i>
                 Probability and inductive logic
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                link-opacity-50
                "
                href="javascript:;"
              >12. 
                <i class="bi bi-lock-fill"></i>
                 Logic-based learning
              </a>
            </li>
            
          </ul>
        </div>
          
      </li>
      
      
      <hr>
      <li class="nav-item">
        <div class="d-flex flex-row">
          <div class="container">
            <a class="nav-link " href="/slides/"><i class="bi bi-rocket-takeoff-fill"></i> &nbsp;&nbsp; Slides</a>
          </div>
          <button 
            class="btn btn-sm btn-dark" 
            href="/slides/"
            id="navbarSectionsli-home" data-bs-toggle="collapse"
            data-bs-target="#collapsesli-home"  
            aria-expanded="aria-expanded=false"
            aria-controls="collapsesli-home">
            <i class="bi bi-caret-left-fill toggle-icon"></i>
          </button>
        </div>
        <div class="collapse " id="collapsesli-home">
          <ul class="list-unstyled ms-3">
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/teaser/"
              >0. 
                <i class="bi bi-unlock-fill"></i>
                 Preamble
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/logic-and-ai/"
              >1. 
                <i class="bi bi-unlock-fill"></i>
                 Logic and AI
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/formal-languages/"
              >2. 
                <i class="bi bi-unlock-fill"></i>
                 Formal languages
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/valid-inference/"
              >3. 
                <i class="bi bi-unlock-fill"></i>
                 Valid inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/boolean/"
              >4. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean algebra
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/sat/"
              >5. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean satisfiability
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/conditionals/"
              >6. 
                <i class="bi bi-unlock-fill"></i>
                 Logical conditionals
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/proof/"
              >7. 
                <i class="bi bi-unlock-fill"></i>
                 Logical proofs
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/fol/"
              >8. 
                <i class="bi bi-unlock-fill"></i>
                 FOL
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/fol-inference/"
              >9. 
                <i class="bi bi-unlock-fill"></i>
                 FOL Inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/many-valued/"
              >10. 
                <i class="bi bi-unlock-fill"></i>
                 Many-valued Logic
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/slides/probability/"
              >11. 
                <i class="bi bi-unlock-fill"></i>
                 Probability and inductive logic
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                link-opacity-50
                "
                href="javascript:;"
              >12. 
                <i class="bi bi-lock-fill"></i>
                 Logical learning
              </a>
            </li>
            
          </ul>
        </div>
          
      </li>
      
      
      <hr>
      <li class="nav-item">
        <div class="d-flex flex-row">
          <div class="container">
            <a class="nav-link " href="/exercises/"><i class="bi-gear-fill"></i> &nbsp;&nbsp; Exercises</a>
          </div>
          <button 
            class="btn btn-sm btn-dark" 
            href="/exercises/"
            id="navbarSectionexe-home" data-bs-toggle="collapse"
            data-bs-target="#collapseexe-home"  
            aria-expanded="aria-expanded=false"
            aria-controls="collapseexe-home">
            <i class="bi bi-caret-left-fill toggle-icon"></i>
          </button>
        </div>
        <div class="collapse " id="collapseexe-home">
          <ul class="list-unstyled ms-3">
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/preamble/"
              >0. 
                <i class="bi bi-unlock-fill"></i>
                 Preamble
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/logic-and-ai/"
              >1. 
                <i class="bi bi-unlock-fill"></i>
                 Logic and AI
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/formal-languages/"
              >2. 
                <i class="bi bi-unlock-fill"></i>
                 Formal languages
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/valid-inference/"
              >3. 
                <i class="bi bi-unlock-fill"></i>
                 Valid inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/boolean/"
              >4. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean algebra
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/sat/"
              >5. 
                <i class="bi bi-unlock-fill"></i>
                 Boolean satisfiability
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/conditionals/"
              >6. 
                <i class="bi bi-unlock-fill"></i>
                 Logical conditionals
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/proof/"
              >7. 
                <i class="bi bi-unlock-fill"></i>
                 Logical proofs
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/fol/"
              >8. 
                <i class="bi bi-unlock-fill"></i>
                 FOL
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/fol-inference/"
              >9. 
                <i class="bi bi-unlock-fill"></i>
                 FOL inference
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/exercises/many-valued/"
              >10. 
                <i class="bi bi-unlock-fill"></i>
                 Many-valued logics
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                link-opacity-50
                "
                href="javascript:;"
              >11. 
                <i class="bi bi-lock-fill"></i>
                 Logic and probability
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                link-opacity-50
                "
                href="javascript:;"
              >12. 
                <i class="bi bi-lock-fill"></i>
                 Logical learning
              </a>
            </li>
            
          </ul>
        </div>
          
      </li>
      
      
      <hr>
      <li class="nav-item">
        <div class="d-flex flex-row">
          <div class="container">
            <a class="nav-link " href="/assignments/"><i class="bi bi-house-gear-fill"></i> &nbsp;&nbsp; Assignments</a>
          </div>
          <button 
            class="btn btn-sm btn-dark" 
            href="/assignments/"
            id="navbarSectionass-home" data-bs-toggle="collapse"
            data-bs-target="#collapseass-home"  
            aria-expanded="aria-expanded=false"
            aria-controls="collapseass-home">
            <i class="bi bi-caret-left-fill toggle-icon"></i>
          </button>
        </div>
        <div class="collapse " id="collapseass-home">
          <ul class="list-unstyled ms-3">
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/assignments/assignment_1/"
              >1. 
                <i class="bi bi-unlock-fill"></i>
                 Assignment 1 (due 09/19/2025)
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/assignments/assignment_2/"
              >2. 
                <i class="bi bi-unlock-fill"></i>
                 Assignment 2 (due 03/10/2025)
              </a>
            </li>
            
            <li>
              <a class="dropdown-item 
                
                
                "
                href="/assignments/assignment_3/"
              >3. 
                <i class="bi bi-unlock-fill"></i>
                 Assignment 3 (due 24/10/2025)
              </a>
            </li>
            
          </ul>
        </div>
          
      </li>
      
      
      
      
      
    </ul>
  </div>
</div>



    <header class="align-self-center d-flex flex-column m-0 mb-md-1 p-0" data-bs-theme="dark">
      <nav class="navbar bg-dark shadow" data-bs-theme="dark" aria-label="header-navbar">
  <div class="container-sm align-self-center px-3">
    <a class="navbar-brand fs-6" href="https://logicalmethods.ai/">
    <img src="https://logicalmethods.ai/img/nav_id.png" class="inert-img img-fluid m-2" draggable="false" width="400px">
    </a>
    <button class="navbar-toggler border-0" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas-nav" aria-controls="offcanvas-nav">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>
</nav>

      
      
    </header>
    
    <main class="align-self-center d-flex flex-column flex-fill bg-white m-md-1 p-0" data-bs-theme="light">
      <ul class="navbar-nav flex-row justify-content-center mt-2">

  <li class="nav-item">
    <a href="/textbook/" class="btn" style="font-size: 20pt;" tabindex="-1" role="button" aria-disabled="false">
      <i class="bi bi-house-up"></i>
    </a>
  </li>
</ul>
<div class="container chapter">
  <p>By: <em>Colin Caret and Johannes Korbmacher</em></p>
  <div class="m-4"><h1 id="valid-inference">Valid inference<button class="btn btn-back-to-top">
    
  </button>
</h1>
<hr>

<p>Inference is everywhere in AI. We&rsquo;ve seen how deductive inference occurs on the
level of circuits using Shannon&rsquo;s interpretation, we&rsquo;ve mentioned that <abbr title="large language models, such as GPT, Claude, Llama, ..."><a  class="link-underline-opacity-0 link-body-emphasis"> LLMs</a></abbr>
use a form of inductive inference to predict pieces of text, and, of course, any
<i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/Artificial_General_Intelligence"
  target="_blank">artificial general intelligence
(AGI)</a> would need
to be able perform valid inferences, like our first example:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/socrates_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="400px"  alt="" >

<p>So what precisely makes an inference valid? What distinguishes good from bad
inferences, both in deductive and inductive reasoning?—In this chapter, we&rsquo;ll
deep dive into the logical theory of valid inference.</p>
<p>At the end of the chapter, you&rsquo;ll be able to:</p>
<ul>
<li>explain the relevance of logical form to valid inference,</li>
<li>explain the difference between material (domain-specific) and logical
(domain-general) validity</li>
<li>distinguish deductively valid from invalid inferences in terms of
truth-preservation</li>
<li>distinguish inductively strong from inductively weak inferences in terms of probability raising</li>
</ul>
<h2 id="correctness">Correctness<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>When we talk about validity, we are talking about a <em>good feature</em> of inferences,
but this is not the only good feature an inference can have. For example, it is
good for inferences to be simple, clear, precise, economical, etc. Logic does
not deal with all of these topics. Most of these topics are part of <strong>rhetoric</strong>,
the study of persuasive writing style. Logic deals with <em>validity</em>.</p>
<p>Validity is a standard of <strong>correctness</strong> for inferences. To really fix this
concept, it might help to think about it from the other direction. What happens
if an inference <em>lacks</em> validity, when it is <strong>invalid</strong>? Well, that shows us
that something went wrong. The inference made a <em>mistake</em>. Some of these logical
mistakes or <strong>fallacies</strong> are so famous that they have their own names.</p>
<p>Here is an example of a fallacy called <em>affirming the consequent</em>:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/cycling_invalid.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/ai_cycling_rain.png" class="rounded  float-end inert-img img-fluid"  width="400px"  alt="" >

The mistake should be clear. The
<abbr title="&#39;if  ..., then ...&#39; statement"><a  class="link-underline-opacity-0 link-body-emphasis"> conditional</a></abbr> premise says that sun leads
to sport. However, the other premise of this inference is not <em>about</em> sunny
weather, so those two premises don&rsquo;t really &ldquo;add up&rdquo; to anything useful. They
certainly do not support the conclusion that it is sunny today.</p>
<p>Contrast this with the following valid inference:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/cycling_valid.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

<p>This inference involves a premise about sunny weather, which connects with the
conditional premise in the right way. This inference is valid because it uses
all of its premises correctly. These two examples show that it can be easy to
confuse valid and invalid inferences if we don&rsquo;t pay attention to the details.
At a glance, the two inferences look pretty similar.
<img src="https://logicalmethods.ai/textbook/valid-inference/img/ai_cycling_sun.png" class="rounded  float-start inert-img img-fluid"  width="400px"  alt="" >
</p>
<p>This is why logic aims for a <em>systematic</em> definition of validity. This notion
should be applicable not only to humans but to any information-processing
system. It can tell us what counts as <em>intelligent</em> behavior. Without a
definition of correct reasoning, how do we even know what we want AI to achieve?</p>
<p>So, we would like to say, in general, what <em>makes</em> an inference valid or
invalid. The standard idea is that valid inferences <strong>preserve truth</strong> from
their premises to their conclusion.</p>
<h2 id="hypothetically">Hypothetically<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>To test whether an inference is valid, we ask if the conclusion is true <em>when</em>
the premises are true. This is a <strong>hypothetical</strong> question. Answering this
question does not require us to know that the premises really <em>are</em> true. In
fact, we can make a stronger point: it is possible to have an inference that is
valid even though it has false premises. Here is an example.</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/ei_can_fly.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

<p>The <em>reasoning</em> behind this inference is perfectly correct. The conclusion
follows from the premises. That makes the inference valid. But we obviously know
that this inference also involves some false premises. Cats can&rsquo;t really fly.</p>
<p>The important point is that validity is not determined by the actual truth or
falsity of statements. What we care about is the <em>connections between</em>
statements.</p>
<p>When we test for validity, we do not look at the actual truth of premises and
conclusion, instead we look for a <strong>relationship</strong> between their truth-values.
You can think about it like this: imagine that the premises and true and think
about whether the conclusion is true <em>under this assumption</em>.</p>
<p>Think about the inference this way. When we do this, we imagine a world that is
slightly different from the actual world, a world where cats do fly. In that
kind of world, it has to be true that <span style="margin-right:-4px;vertical-align: middle;transform-origin: 50%  49%;transform:rotate(180deg);display:inline-block">IE</span>
 flies.</p>
<p>This is the basic idea of truth-preservation:</p>
<p class="text-center">
<span class="excalifont ">
  An inference is valid <abbr title="if and only if">iff</abbr> the conclusion
  is true under the (hypothetical) assumption that the premises are true.
</span>

<p>Now, we can ask a series of follow-up questions. How tight is the
truth-preservation relationship? How often does it have to hold? How reliable
does an inference need to be in order to call it &ldquo;valid&rdquo;? Different answers to
these questions take us in two directions: deductive and inductive logic.</p>
<h2 id="formally--logical-validity">Formally &ndash; Logical validity<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>Take our first example again:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/socrates_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="400px"  alt="" >

<p>This is, of course, a valid inference: under the assumption that the premises
are true, so is the conclusion. But note that for this, it doesn&rsquo;t matter that
we&rsquo;re talking about Socrates or mortality. If we change the term

<span class="excalifont "> Socrates</span>
 to, say,

<span class="excalifont ">Alan Turing</span>
, and we change the <abbr title="expression that ascribes a property"><a  class="link-underline-opacity-0 link-body-emphasis"> predicates</a></abbr>

<span class="excalifont ">human</span>
 and 
<span class="excalifont ">mortal</span>

to, say, 
<span class="excalifont ">mathematician</span>
 and 
<span class="excalifont ">smart</span>
,
we&rsquo;d get the following inference, which is also valid:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/turing_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

<p>Also our example from above about <span style="margin-right:-4px;vertical-align: middle;transform-origin: 50%  49%;transform:rotate(180deg);display:inline-block">IE</span>
 being able to fly is the
result of changing 
<span class="excalifont ">Socrates</span>
 to

<img src="https://logicalmethods.ai/textbook/valid-inference/img/there_is.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
,

<span class="excalifont ">human</span>
 to 
<span class="excalifont ">cat</span>
, and 
<span class="excalifont ">mortal</span>
 to 
<span class="excalifont ">can fly</span>
. In fact, for <em>every</em> way of replacing terms and predicates like this, the inference remains valid.</p>
<p>In logical theory, we say that the argument is valid <em>in virtue of its logical
form</em>. We can express the shared <strong>logical form</strong> of the inferences in question
as follows:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/syllogism_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="800px"  alt="" >

Here, the <span class="excalifont">A</span> and
<span class="excalifont">B</span> are placeholders for arbitrary predicates,
and the lower-case <span class="excalifont">c</span> is an arbitrary term. The
idea is that whichever expressions we put in for
<span class="excalifont">A,B</span> and <span class="excalifont">c</span>, as
long as they&rsquo;re of the right grammatical category, we&rsquo;ll get a valid inference.
By representing the logical form of our inference in this way, we&rsquo;re
<em>abstracting away</em> from the logically irrelevant predicates and terms and obtain
an abstract representation of the logical form.</p>
<p>So far, we&rsquo;ve discussed the idea of logical form in natural language. But as
we&rsquo;ve discussed in the previous chapter, for the purposes of AI research, we
need to work in <em>formal</em> languages. We haven&rsquo;t encountered a formal language
yet that is expressive enough to represent our inference about Socrates, but we
can illustrate the point with relation to <abbr title="modus ponens"><a  class="link-underline-opacity-0 link-body-emphasis"> MP</a></abbr>, which is the following inference schema, introduced in the previous
chapter:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/modus_ponens.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

In the language of propositional logic, we can express this logical form more
precisely using the logical operators we&rsquo;ve introduced in the previous chapter.
Remember that 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/conditional.png" class="inert-img" height="18px"  style="ZgotmplZ" alt="" >
 represents the natural language &ldquo;if …, then …&rdquo;. In formal
languages, we let letters like <span class="excalifont">A,B</span> represent
arbitrary formulas, like in the schema we wrote before. So, in purely formal
terms, we can write the inference as:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/mp_schematic.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="200px"  alt="" >

To be able to write this in one line, we also use the symbol 
<span class="excalifont ">
<img src="/img/therefore.png" alt="Therefore" class="inline-icon" style="height:1em;width:auto;"/>
</span>
 (read &ldquo;therefore&rdquo;) in place of the inference line like so: 
<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) 
<img src="/img/therefore.png" alt="Therefore" class="inline-icon" style="height:1em;width:auto;"/>
 C</span>
.</p>
<p>To express the logical claim that <abbr title="modus ponens"><a  class="link-underline-opacity-0 link-body-emphasis"> MP</a></abbr>
is valid we use the logical symbol <span class="excalifont">⊨</span>, which is
called the &ldquo;double turnstile&rdquo; or &ldquo;models&rdquo; (for reasons we&rsquo;ll get into later).
So, we write the validity of MP in purely formal notation as 
<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) ⊨ B</span>
.</p>
<p>By the way, it&rsquo;s important to distinguish between the inference

<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) 
<img src="/img/therefore.png" alt="Therefore" class="inline-icon" style="height:1em;width:auto;"/>
 B</span>
 and its validity

<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) ⊨ B</span>
: there are logical systems where
MP is <em>not</em> valid. In those contexts, an AI system might
still—fallaciously—reason according to MP, i.e. it might apply 
<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) 
<img src="/img/therefore.png" alt="Therefore" class="inline-icon" style="height:1em;width:auto;"/>
 C</span>
 even though, in this context, 
<span class="excalifont ">A, (A 
<img src="/img/to.png" alt="Implication" class="inline-icon" style="height:1em;width:auto;"/>
 B) ⊭ B</span>
.</p>
<p>Validity in virtue of logical form, as just discussed, is known as <strong>logical
consequence</strong>. But, importantly, not <em>all</em> valid inferences are logically
valid—valid in virtue of their logical form. Consider the following inference,
for example:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/uncle_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

<p>Following the truth-preservation criterion, this inference is certainly valid.
Under the assumption that 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/sigma_premise.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >

it&rsquo;s true that 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/sigma_conclusion.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >

since an uncle is, by definition, a parent&rsquo;s male sibling.</p>
<p>But if we replace <span class="excalifont">brother</span> with <span class="excalifont">sister</span>, for example, we get the following <em>in</em>valid inference:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/sigma_aunt.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >

If we assume that <span class="excalifont">Σ</span> is <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
&rsquo;s mother&rsquo;s
sister, <span class="excalifont">Σ</span> is <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
&rsquo;s aunt and not their
uncle. This shows that the inference is not valid in virtue of its form, which
is something like:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/form_uncle.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="500px"  alt="" >
</p>
<p>But the inference <em>is</em> valid … in a sense. The validity of the inference depends
on the concrete predicates involved—the
meanings of <span class="excalifont">brother</span>,
<span class="excalifont">mother</span>, and
<span class="excalifont">uncle</span>. In logical theory, we also call
inferences like this, which are valid, but not in virtue of their logical form,
<strong>materially valid</strong>. While logical validity—validity in virtue of logical
form—is is <strong>domain-general</strong>, material validity is <strong>domain-specific</strong>. As
we&rsquo;ve seen, for the validity of our inference about Socrates it doesn&rsquo;t matter
that we&rsquo;re talking about Socrates, being human, or being mortal, but for the
validity of our inference about <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
&rsquo;s uncle, it does matter that we&rsquo;re
talking about his mother&rsquo;s brother and not sister.</p>
<p>This means that the classification of valid inferences we&rsquo;ve discussed before
needs to be further qualified on the deductive side:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/logical_material.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="700px"  alt="" >

<p>The distinction between domain-general and domain-specific inference is crucial
to understand some recent advances in AI research: while <abbr title="large language models"><a  class="link-underline-opacity-0 link-body-emphasis"> LLMs</a></abbr> are getting better and better at
domain-<em>specific</em> inference, such as inference in mathematics, they are still
underperforming in domain-<em>general</em>, logical inference. Some researchers speculate
that improving the domain-general reasoning abilities of AI systems improves
their domain-specific reasoning abilities as well.</p>
<p>There is close connection between logical and material validity. Some
logician&rsquo;s, like <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://de.wikipedia.org/wiki/Rudolf_Carnap"
  target="_blank">Rudolf Carnap</a>,
have suggested that we can <em>reduce</em> material validity to a special case of
logical validity under additional assumptions, so-called &ldquo;meaning postulates&rdquo;.
His idea is based on the observation that the material validity of the inference
about <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
&rsquo;s uncle can be expressed in the <em>logical</em> validity of the
following inference:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/valid_uncle.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="700px"  alt="" >

Here the statement 
<span class="excalifont ">the brother of a person's mother is their
uncle</span>
 is a meaning postulate, which captures (part of) the
meaning of the term 
<span class="excalifont ">uncle</span>
.
While</p>
<h2 id="always--deductive-validity">Always &ndash; Deductive validity<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>We&rsquo;ve previously defined a deductively valid inference to be one where the
premises <em>necessitate</em> the conclusion. We can think of this as stipulating that
truth-preservation <em>always</em> holds. In deductive inferences, we want 100%
reliability in all situations whatsoever. No exceptions allowed. <em>Necessarily</em>,
in any situation where the premises are true, the conclusion is true as well.
Otherwise, if there&rsquo;s a situation where the premises are true and the conclusion
isn&rsquo;t, the inference is deductively <em>in</em>valid. This is a high standard we are
asking for but it is very useful when we can identify this kind of air-tight
reasoning.</p>
<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/ai_asteroid.png" class="rounded  float-start inert-img img-fluid mx-3"  width="400px"  alt="" >

Deductive reasoning is characteristic of <strong>mathematical inference</strong>, which we
encounter not only in pure math, but also in applications of mathematics in
physics and the natural sciences. When we make predictions, for example, about
the trajectory of an asteroid heading towards earth, this involves a lot of
deductive, mathematical reasoning. We start with some empirical observations
and apply physical laws, but the actual calculation is deductive. That means
that, assuming the calculations are carried out correctly, the result is as
certain as the observation: the only reason why the prediction could be wrong
is that the assumptions—the laws or observations—are wrong.</p>
<p>Since the rules for deductive logic are <em>indefeasible</em>, they are suited to
<strong>belief accumulation</strong>. These rules do not vary between contexts. They do not
require special justification. There is nothing that can make these rules fail.
Nothing can defeat a deductively valid inference.</p>
<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/fox.png" class="rounded  float-end inert-img img-fluid mx-3"  width="300px"  alt="" >

The optimal way of using deduction is to take a set of existing beliefs (or
knowledge) and then add more beliefs (or knowledge) by applying logical rules.
A common, real world <em>implementation</em> of deductive reasoning occurs whenever we
apply some general pattern to a specific case. For example,
<i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/Fox"
  target="_blank">vixens</a> are female foxes. That is the
definition of the concept <em>vixen</em>. Suppose you know this and you hear someone
say &ldquo;there is a vixen living in the forest!&rdquo;. In that case, you might use
deduction to infer that there is a fox living the forest.—This kind of
deductive inference should be carried out by any reasoning AI system, such as
expert systems, but also reasoning <abbr title="large language models"><a  class="link-underline-opacity-0 link-body-emphasis"> LLMs</a></abbr>, such as OpenAI&rsquo;s <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/OpenAI_o4-mini"
  target="_blank">o4-mini</a> or Deepseek&rsquo;s <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/DeepSeek"
  target="_blank">R1</a>.</p>
<p>Moreover, many <strong>programming languages</strong> are essentially formal languages with
deductive rules. This is a perfect way to apply logical methods. Consider the
code snippet below. This simple Python snipped is supposed to take an input
that is a whole number and identify whether it is a positive number or not:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/python.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="600px"  alt="" >

<p>Imagine what would happen if the computer did, effectively, not obey deductive
rules like &ldquo;modus ponens&rdquo;. We would have no idea what to expect when we run this
program. Sometimes when you ran the program and entered the number 1, you might
get the correct answer that 1 is a positive number, but other times you might
you get no answer at all. That would be useless and frustrating. In order to
make the behavior of programs predictable, we want them to effectively follow
deductive rules of reasoning.</p>
<p>We&rsquo;ve already encountered some examples of deductively valid inferences, like
the one concerning Socrates&rsquo; mortality. Here are some further examples of
inference <em>schemas</em>, which are often considered to be deductively valid in
propositional logic:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/inference_patterns.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="700px"  alt="" >

<p>Similarly, we&rsquo;ve seen some inference patterns that may seem deductively valid,
but are generally agreed to be <strong>fallacies</strong>:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/propositional_fallacies.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="700px"  alt="" >

<p>One of the central aims of deductive logic is to provide a <strong>theory of
deductively valid inference</strong> which can account for the apparent deductive
validity and invalidity of the above inference schemas.</p>
<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/there_is_wants.png" class="rounded  float-end inert-img img-fluid mx-3"  width="300px"  alt="" >

The standard approach to developing such an account is the <strong>semantic
approach</strong>. The basic tool it uses is that of a <strong>semantic model</strong>. A semantic
model is like a picture of a possible reasoning scenario. Think for example of
the scenario we considered above, where all cats—and thus <span style="margin-right:-4px;vertical-align: middle;transform-origin: 50%  49%;transform:rotate(180deg);display:inline-block">IE</span>
—could fly. If we look
at a model, we can ask whether a specific sentence
<span class="excalifont">A</span> is true or not in that model. Every model
gives an answer. It assigns a definite truth-value to each sentence. If we take
the sentence 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/there_is.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
<span class="excalifont"> can fly</span>
and consider the scenario, where cats can fly, we get the answer that the
sentence is <em>true</em>. But if we evaluate the sentence relative to the way things
actually are, the answer is that it&rsquo;s not <em>true</em>.</p>
<p>In logical theory, semantic models are defined relative to a formal language
and the concrete definition of a model depends on the specifics of the language
under consideration. In fact, as we&rsquo;ll see a lot of work goes into defining the
notion of a model with mathematical precision. So, we&rsquo;ll have to postpone this
to later lessons. But what we <em>can</em> talk about is the general pattern that all
semantic definitions of deductively valid inference follow.</p>
<p>For this, let&rsquo;s assume that we&rsquo;re dealing with a formal language 
<span class="excalifont ">L</span>
, defined in terms of an alphabet and grammar,
for which we&rsquo;ve defined the notion of a model, such that for every model 
<span class="excalifont ">M</span>
 for 
<span class="excalifont ">L</span>

each formula 
<span class="excalifont ">A</span>
 of 
<span class="excalifont ">L</span>
 is either true or not. Generally speaking, a formal language
has more than one model. Different models assign different values to the same
sentences. In one model perhaps 
<span class="excalifont ">A</span>
 is true
and  
<span class="excalifont ">B</span>
 is not. In another model 
<span class="excalifont ">B</span>
 is true and  
<span class="excalifont ">A</span>
 is not. That variation allows models to picture different
scenarios.</p>
<p>Now it&rsquo;ll be helpful to talk about
<abbr title="collection of objects"><a  class="link-underline-opacity-0 link-body-emphasis"> sets</a></abbr> again.
Remember that a set is collection of arbitrary objects, <em>anything</em> can be in a
set—even abstract mathematical objects like models. So for each formula 
<span class="excalifont ">A</span>
, we can consider the set of models where
the formula is true. We write this as 
<span class="excalifont ">[A]</span>
.
Using the set-theoretic notation we introduced when talking about formal
languages, we can write an explicit definition of this set using set abstraction:
<p class="text-center">
<span class="excalifont ">[A] = { M : M is a model, where A is true} </span>
</p>
<p>It can be helpful to imagine this set as part of a <strong>logical space</strong> of models.
In the diagram below, we assume that every model 
<span class="excalifont ">M</span>
 for our language 
<span class="excalifont ">L</span>

&ldquo;lives&rdquo; in the yellow rectangle. We depict them as little blue balls or
&ldquo;worlds&rdquo;. The green set (region) inside it is the set of all models where 
<span class="excalifont ">A</span>
 is true, i.e. 
<span class="excalifont ">[A]</span>
:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/logical_space.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="900px"  alt="" >

<p>The set 
<span class="excalifont ">[A]</span>
 is also called the
<strong>proposition</strong> expressed by the formula 
<span class="excalifont ">A</span>
.
The set 
<span class="excalifont ">[A]</span>
 represents, as it were, the
<em>semantic content</em> of the formula 
<span class="excalifont ">A</span>
 from a
logical perspective.</p>
<p>We can use this picture of logical space to define the notion of deductively
valid inference, but first we need another bit of set theory. When all the
members of one set, 
<span class="excalifont ">S</span>
, are
also members of another set, 
<span class="excalifont ">T</span>
, we say
that the set 
<span class="excalifont ">S</span>
 is a <strong>subset</strong> of 
<span class="excalifont ">T</span>
. Symbolically, we write: 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/subset.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
. When there is at least one member in 
<span class="excalifont ">S</span>
 that is not in 
<span class="excalifont ">T</span>
, then 
<span class="excalifont ">S</span>
 is not a subset of 
<span class="excalifont ">T</span>
, symbolically: 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/nsubset.png" class="inert-img" height="38px"  style="ZgotmplZ" alt="" >
.</p>
<p>Take, for example, the set that contains little Jimmy, the set
that contains the number one and my beer, as well as Mr. Sir:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/set_big.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="400px"  alt="" >

<p>Then consider the set that contains only little Jimmy and Mr. Sir:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/set_small.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="200px"  alt="" >

<p>Then the latter set is a subset of the former, since both elements of the latter set—little Jimmy and Mr. Sir—are also members of the latter set:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/set_subset.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="600px"  alt="" >

<p>The set that contains Mr. Sir and my beer, in contrast, is not a subset:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/big_set_nsubset.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="600px"  alt="" >

<p>This is because the set contains my beer, which is not a member of the bigger set:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/nsubset_ex.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="800px"  alt="" >

<p>Graphically, the subset-relation amounts to one set being &ldquo;enclosed by&rdquo; another:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/sub_vs_nsub.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="800px"  alt="" >

<p>In the case of a simple inference (in a formal language), with just one premise

<span class="excalifont ">P</span>
 and conclusion 
<span class="excalifont ">C</span>
,
we can directly understand deductive validity in terms of the subset relation.</p>
<p>The idea is that we can understand truth-preservation—the idea that the
conclusion is true under the hypothesis that the premises are true—can be
spelled out using models:</p>
<p class="text-center">
<span class="excalifont ">
<strong>Single-premise deductive validity</strong><br>

=<br>

In every model, where the premise P is true, the
conclusion C must be true as well. 
</span>

<p>But in set-theoretic terms that just means that the set of models of the premise
is a <em>subset</em> of the set of models of the conclusion: 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/single_premise_validity.png" class="inert-img" height="38px"  style="ZgotmplZ" alt="" >
.</p>
<p>That is, for the inference from 
<span class="excalifont ">P</span>
 to 
<span class="excalifont ">C</span>
 to be valid, the situation needs to be like the
one depicted here:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/p_entails_c.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="800px"  alt="" >

<p>If, instead, there is a model where 
<span class="excalifont ">P</span>
 is
true but 
<span class="excalifont ">C</span>
 is not, if there is a
<strong>countermodel</strong> as depicted here, the inference is deductively invalid:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/p_nentails_c.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="800px"  alt="" >

<p>To generalize this idea to arguments with multiple premises, we need one final
set-theoretic concept. The <strong>intersection</strong> of two sets

<span class="excalifont ">S</span>
 and 
<span class="excalifont ">T</span>
,
denoted 
<span class="excalifont ">S ∩ T</span>
  is
the set that contains all and only the elements that are in <em>both</em> sets, i.e.</p>
<p class="text-center">
<span class="excalifont ">S ∩ T = { a : a ∈ S and a ∈ T}</span>

<p>Visually, the idea of intersection can be represented as in the following
diagram, where the intersection of 
<span class="excalifont ">S</span>
 and 
<span class="excalifont ">T</span>

is indicated by the shaded area:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/intersection_img.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="800px"  alt="" >

<p>So, for example, the intersection of the set containing little Jimmy and Mr. Sir
and the set containing little Jimmy and the number one is the set containing
just little Jimmy:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/intersection_calc.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="600px"  alt="" >

<p>When we have an inference with multiple premises

<span class="excalifont ">P₁</span>
, 
<span class="excalifont ">P₂</span>
, …, and conclusion 
<span class="excalifont ">C</span>
,
we want to say that this inference is deductively valid just in case whenever
all the premises are true, so is the conclusion. That is:</p>
<p class="text-center">
<span class="excalifont ">

<strong>General deductive validity</strong><br>

=<br>

In every model, where P₁, P₂, … are all true, the
C must be true as well. 
</span>

<p>But we can describe the models where 
<span class="excalifont ">P₁</span>
,

<span class="excalifont ">P₂</span>
, … are true in terms of the sets

<span class="excalifont ">[P₁]</span>
, 
<span class="excalifont ">[P₂]</span>
, …,
where each individual formula is true:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/premise_intersection.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="600px"  alt="" >

<p>This gives us the final definition deductively valid inference:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/validity_general.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="600px"  alt="" >

<p>So, for an inference with two premises <span class="excalifont">P,Q</span> and
conclusion <span class="excalifont">C</span> to be valid, the situation needs
to like the one depicted here:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/valid_multi_premise.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="900px"  alt="" >

<p>An example of a set-up, where the inference from <span class="excalifont">P,Q</span>  to <span class="excalifont">C</span> is <em>in</em>valid is depicted here:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/invalid_multi_premise.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="900px"  alt="" >

<p>This is, in abstract terms, the standard logical theory of deductive inference.
But it is <em>truly</em> abstract: we haven&rsquo;t defined yet what a model really is. To
obtain a workable definition for a concrete language—like the language of
propositional logic—we need to supply the notion of a model for that language.
What we have is a sort of <strong>blueprint</strong> for deductive validity: for any
language, if we supply a definition of a model for that language and say what it
means for a formula to be true in such a model, we obtain the notion of
deductively valid inference in that language.</p>
<p>So, if we want to show that disjunctive syllogism is deductively valid in
propositional logic, for example, we need to show that:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/valid_ds.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="500px"  alt="" >

<p>That is, we need to show that in all models where 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/a_or_b.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
 and 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/neg_a.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
 are both true, <span class="excalifont">B</span> is true as well.</p>
<p>Similarly, if we want to show that denying the antecedent is</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/invalid_dc.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="500px"  alt="" >

<p>That is we need to show that there&rsquo;s a model where 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/a_to_b.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
 and 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/neg_a.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
 are true, but 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/neg_b.png" class="inert-img" height="30px"  style="ZgotmplZ" alt="" >
 is not.</p>
<p>To be able to do this, we need the notion of a model for the language of
propositional logic and conditions when negations, disjunctions, conditionals,
and so on are true in them—providing this is the core task of semantic theory.</p>
<p>The concept of deductive validity is specialized. It makes sense to use
deductive reasoning for specific tasks: reasoning in mathematics or other
specific theories, reasoning with precisely defined concepts or pattern that
are truly general. Notice how this air-tight reasoning is not quite the same
thing as what Sherlock Holmes calls &ldquo;doing a deduction&rdquo;:</p>
<div class="container " >
  <figure>
    <blockquote class="blockquote fs-6">
      <p>
      “From a drop of water&hellip; a logician could infer the possibility of an Atlantic
or a Niagara without having seen or heard of one or the other. So all life is
a great chain, the nature of which is known whenever we are shown a single
link of it. Like all other arts, the Science of Deduction and Analysis is one
which can only be acquired by long and patient study&hellip;&quot;
      </p>
    </blockquote>
    
    <figcaption class="blockquote-footer text-end">
      A study in scarlet, 1887
    </figcaption>
    
  </figure>
</div>

<p>Sherlock uses the word &ldquo;deduction&rdquo; for any reasoning that is careful,
systematic, and reliable. However, the examples in this passage sounds a lot
like inductive reasoning. Take a small sample and make an educated guess about
the larger collection that it belongs to. That kind of reasoning is not
indefeasible, it does not make a necessary connection. <em>We</em> do not call that
deduction.</p>
<h2 id="mostly">Mostly<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>With <strong>inductively valid</strong> inference, truth-preservation <em>mostly</em> holds. We&rsquo;ve
defined an inductively valid inference as one where if  the premises are true,
the conclusion is <em>probably</em> true. The likelihood could be slightly increased
(weak induction) or greatly increased (strong induction). Either way, assuming
that the premises are true gives us <em>some</em> reason to believe the conclusion is
true. Inductive inference is not air-tight. There is a chance of going from
truth to falsity, but that is a risk we have to take when we are dealing with
uncertain information.</p>
<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/smoke_fire.png" class="rounded mx-2 float-start inert-img img-fluid"  width="400px"  alt="" >

The study of induction also has roots in ancient philosophy and psychology. The
Buddhist scholars, and brothers, <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://plato.stanford.edu/entries/logic-india/"
  target="_blank">Asaṅga and
Vasubandhu</a> focused on
inferences like &ldquo;where there is smoke, there is fire&rdquo;. They considered
associative thinking, tracking regularities in experience, and drawing
structural analogies to be the cornerstones of real human belief-forming
practices. This was an attempt to describe how the mind really functions to help
us navigate a world where evidence is imperfect.</p>
<p>Inductive reasoning is characteristic of <strong>scientific
inference</strong>, especially in disciplines where statistical empirical research
plays an important role. For example, we commonly use <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/Randomized_controlled_trial"
  target="_blank">randomized control
trials</a> in medical
research to determine the whether a drug is effective. Very roughly, the idea is
that we randomly allocate participants a drug or placebo (or the like) and see
if one group (drug or placebo) has significantly better outcomes. Along the way,
we control for various confounding factors. If the group with the drug has
better outcome than the other, we conclude that the drug is effective. This is,
ultimately, a form of inductive inference: we infer that a drug works from the
fact that it has worked in many cases, which have been well-sampled.—The
complete story is, of course, much more complicated (how <em>do</em> we guarantee that
we sample well, what does &ldquo;significantly better&rdquo; mean, …), but at the heart of
this lies inductive inference.</p>
<p>
<img src="https://logicalmethods.ai/textbook/valid-inference/img/ai_rct.png" class="rounded mx-2 float-end inert-img img-fluid"  width="400px"  alt="" >
 Since inductive reasoning is <strong>defeasible</strong>—it can be
overturned by further evidence—it is well-suited to <strong>belief modulation</strong>: to
change our beliefs in light of new evidence. Take the case of smoke means fire,
for example. If <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
 sees smoke coming up behind the trees, it might
think that there&rsquo;s an illegal open camp-fire burning in the woods. But if <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
 learns that that Mr. Sir often smokes his pipe in the forest, he might
change his conclusions. Even though the original evidence didn&rsquo;t go away, it&rsquo;s
been further supplemented by additional information, which changes the
conclusions we draw. In this way, inductive logic is closely related to
<strong>learning from evidence</strong>, which is a core concept of AI research.</p>
<p>Similarly, inductive reasoning play a central role in <strong>prediction</strong>. We make
predictions when we don&rsquo;t know what&rsquo;s going to happen: the weather, what the
stock market will look like tomorrow, and so on. In fact, we&rsquo;ve already
discussed how next-word-prediction is essentially the core concept underlying
recent AI <abbr ><a  class="link-underline-opacity-0 link-body-emphasis"> LLMs</a></abbr></p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/text_prediction.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>The examples we used to motivate the idea of logical form where all deductive
inferences. But also <em>in</em>ductive logic, deals with logic form. Let&rsquo;s revisit
some examples. First, take the inference about swans, perhaps the most
traditional example of an inductive inference:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/swans_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>In light of the well-known fact that there are black swan&rsquo;s we&rsquo;ve slightly
modified the example to a case where <span class="code" style="margin-right:-4px;vertical-align: text-top;transform-origin: 50%  50%;transform:rotate(180deg);display:inline-block">IA</span>
 draws marbles from a jar:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/marbles_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>Note that there&rsquo;s the same kind of pattern going on that we&rsquo;ve observed in the
case of the inference about Socrates&rsquo; mortality: we can replace one predicate
with another and get what looks like another inductively valid inference.</p>
<p>The underlying pattern of this inference is known as <strong>enumerative induction</strong>:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/enumerative_induction_1.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>There are different ways in which enumerative induction is represented. Here&rsquo;s
another:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/enumerative_induction_2.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="350px"  alt="" >

<p>The assumption here is, of course, that 
<span class="excalifont ">a</span>
,

<span class="excalifont ">b</span>
, 
<span class="excalifont ">c</span>
,
… run through a sufficiently large number of instances.</p>
<p>Just like in deductive logic, we can use formal languages to mathematically
represent inductive inferences. Unfortunately, however, to express inference
schemas like enumerative induction, we need more expressive languages than
propositional logic, so this will have to wait. But what we <em>can</em> talk about
now, is how inductive validity is defined in formal languages <em>in general</em>, just
like we did for deductive validity.</p>
<p>In inductive logic, we use the symbol 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/inductive_validity.png" class="inert-img" height="26px"  style="ZgotmplZ" alt="" >
 to stand for
an inductively valid inference, writing

<img src="https://logicalmethods.ai/textbook/valid-inference/img/inductively_valid_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-4"  width="200px"  alt="" >

to say that the inference from the premises

<span class="excalifont ">P₁</span>
, 
<span class="excalifont ">P₂</span>
, …,
to the conclusion 
<span class="excalifont ">C</span>

inductively valid. To say that an inference is inductively <em>strong</em>, we write a

<span class="excalifont ">!</span>
 on top, like so 
<img src="https://logicalmethods.ai/textbook/valid-inference/img/inductively_strong_validity.png" class="inert-img" height="40px"  style="ZgotmplZ" alt="" >
. So if we have a inductively
strong inference going from premises 
<span class="excalifont ">P₁</span>
, 
<span class="excalifont ">P₂</span>
, …,
to conclusion 
<span class="excalifont ">C</span>
 we can
abbreviate this with symbols:

<img src="https://logicalmethods.ai/textbook/valid-inference/img/inductively_strong_inference.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="200px"  alt="" >
</p>
<p>There are different approaches to obtain a semantic definition of inductive
validity, but the most prominent approach involves <strong>probability theory</strong>, which we
use to spell out the idea of the premises making the conclusion more likely.</p>
<p>A straight-forward way for implementing probabilities for the formal languages
of logic &ldquo;piggy-backs&rdquo; on the notion of a model, which we&rsquo;ve used in deductive
logic to define validity. So, we&rsquo;ll be working with a logical space, in which
each formula <span class="excalifont">A</span> has an associated set
<span class="excalifont">[A]</span> of models where it is true.</p>
<p>In inductive logic, we think of these models as ways the world could turn out to
be. If we roll a 6-sided die, for example, there are six ways the world could
turn out to be: it can come up 1, 2, 3, 4, 5, or 6. Each of these corresponds to
a model:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/dice_worlds.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>If in our language we have a formulas <span class="excalifont">EVEN</span> and <span class="excalifont">ODD</span>, for example, to say that the outcome will be even or odd, then these would correspond to the following <abbr title="set of models"><a  class="link-underline-opacity-0 link-body-emphasis"> propositions</a></abbr>:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/even_odd_prop.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>In standard <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/Probability_space"
  target="_blank">probability
theory</a>, such a logical space
is also known as an <strong>sample space</strong>, whose members represent different possible
outcomes. In <em>logical</em> theory, however, the outcomes are just models: possible
reasoning scenarios. The sets of models which we associate with our formulas,
the <em>propositions</em>,  are called <strong>events</strong> in standard probability theory. From
the perspective of logical theory, however, they are just the semantic content
of formulas.</p>
<p>A <strong>probability function</strong> is a mathematical function, which assigns to each
<abbr title="set of models"><a  class="link-underline-opacity-0 link-body-emphasis"> propositions</a></abbr> a real number between 0
and 1—the proposition&rsquo;s <strong>probability</strong>. Well talk about the laws of
probabilities when we discuss concrete systems of inductive logic, but we can
outline the basic ideas of inductive logic without worrying too much about the
details.</p>
<p>In our toy example of a die role, here&rsquo;s one way the probabilities could work
out:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/fair_die.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>This probability distribution corresponds to the assumption that our die is
<em>fair</em>.</p>
<p>But this is not the only way the probabilities could work out. For example, if
we assume that the die we&rsquo;re dealing with is <em>loaded</em>, for example to be much
more likely to roll a six, the probabilities could look like this:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/loaded_die.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>We can use probabilities to mathematically spell out the idea that a conclusion
is <em>likely</em> true on the hypothesis that the premises are. For this, we use the
concept of <strong>conditional probabilities</strong>.</p>
<p>We write <span class="excalifont">Pr([A] | [B])</span> to
denote the conditional probability of <span class="excalifont">A</span> being
true under the hypothesis that <span class="excalifont">B</span> is true. The
standard definition of this is given by the following formula:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/conditional_probability.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="700px"  alt="" >

<p>Here, we crucially need to assume that <span class="excalifont">Pr([B]) ≠ 0</span> to avoid <i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://en.wikipedia.org/wiki/Division_by_zero"
  target="_blank">division by zero</a>.
What this formula says is that the conditional probability  <span class="excalifont">Pr([A] | [B])</span> of <span class="excalifont">A</span> given <span class="excalifont">B</span>
is the &ldquo;part&rdquo; of <span class="excalifont">B</span>&rsquo;s probability that is an <span class="excalifont">A</span>-probability—a measaure of the proportion of <span class="excalifont">A</span> scenarios that are <span class="excalifont">B</span> scenarios.</p>
<p>Here&rsquo;s how this plays out in our previous two distributions if we ask ourselves
what&rsquo;s the probability of the role being a two given that/under the hypothesis
that it&rsquo;s even:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/two_given_even.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="900px"  alt="" >

<p>What we can see here is that the probability of the roll being a two <em>goes up</em>
under the hypothesis that it&rsquo;s even: from  <span class="excalifont">1/3</span>
to <span class="excalifont">1/2</span> in the case of the fair die, and from <span class="excalifont">1/10</span> to <span class="excalifont">1/7</span> in the case of the loaded die. In this sense, the hypothesis that the roll is even <em>supports</em> the conclusion.</p>
<p>You might be worried about this increase of probabilities depending on the
concrete numbers, but in fact, it doesn&rsquo;t. Once we&rsquo;ve introduced the laws of
probability theory, we&rsquo;ll be able to show that for <em>any</em> assignments of
mathematically coherent probabilities the hypothesis that the roll is even will
raise the probability of the roll being a two. This gives us a clear sense of
inductively valid inference:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/final_definition_single.png" class="rounded mx-auto d-block inert-img img-fluid my-5"  width="500px"  alt="" >

<p>The <strong>strength</strong> of the inference can be determined in different ways, but the
most straight-forward one is to look at the absolute increase of probability.
That is, we measure the strength of an inductive inference by:</p>
<div class="text-center my-4 excalifont">strength = | Pr([C] | [P]) - Pr([C]) |</div>
<p>By the way: here the notation <span class="excalifont">| number |</span> stands for the <em>absolute value</em>  of <span class="excalifont"> number </span>, where, for example, <span class="excalifont">| -2 | = | 2 | = 2</span>.</p>
<p>In general, the strength of an inductive inference is going to depend on concrete probabilities. For example, the strength of the inference from even to two assuming a fair die is:</p>
<div class="text-center my-4 excalifont">| 1/3 - 1/6 | = 1/6</div>
<p>Instead assuming the loaded die it&rsquo;s</p>
<div class="text-center my-4 excalifont">| 1/10 - 1/7 | = 3/70</div>
<p>Since <span class="excalifont">1/6 &gt; 3/70</span>, the inference is (much)
stronger assuming a fair die (which makes sense, given that assuming a loaded
die, a six becomes <em>much</em> more likely given that the outcome is even, while
assuming a fair die, all even results go up &ldquo;to the same degree&rdquo;).</p>
<p>This gives us the chance to briefly revisit the distinction between
domain-specific and domain-general, between material and logical validity. When
the concrete probabilities matter in inductive inference, what we&rsquo;re dealing
with is <em>material</em> inductive inference. This kind of inference figures much more
in scientific inference. Logically valid inductive inference is a much rarer
phenomenon, but it underpins the basic principles of belief revision,
prediction, and more.</p>
<p>It remains to generalize the notion of inductively valid inference to inferences
with more than one premise 
<span class="excalifont ">P₁</span>
, 
<span class="excalifont ">P₂</span>
, …, and conclusion 
<span class="excalifont ">C</span>
.
But given what we know now about intersection from the study of deductive
inference, this is pretty straight-forward. The obvious definition is:</p>

<img src="https://logicalmethods.ai/textbook/valid-inference/img/final_definition_multiple.png" class="rounded mx-auto d-block inert-img img-fluid my-2"  width="500px"  alt="" >

<p>Similarly, one straight-forward way of calculating the strength of the inference
is:
<p class="text-center">
<span class="excalifont ">strength = | Pr([C] | [P₁] ∩ [P₂] ∩ …) - Pr([C]) |</span>
</p>
<p>This gives us a blueprint for the study of inductively valid inference: once
we&rsquo;ve supplied a theory of models (which we&rsquo;ll obtain from the study of
deductive inference), all we need to supply is a theory of probabilities and we
obtain a notion of inductively valid inference.</p>
<h2 id="further-readings">Further readings<button class="btn btn-back-to-top">
    
    <i class="bi bi-chevron-double-up"></i>
    
  </button>
</h2>
<hr>

<p>A modern classic on the mathematical definition of deductive validity:</p>
<ul>
<li><i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://doi.org/10.2307/2267371"
  target="_blank">A. Tarski. &ldquo;Über den Begriff der logischen Folgerung&rdquo;. <em>Actes du Congrès
International de Philosophie Scientifique</em>. Hermann, Paris, 1936.</a></li>
</ul>
<p>Update of the Tarskian method, presented at an introductory level:</p>
<ul>
<li><i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://www.cambridge.org/core/books/logical-consequence/CCF10B5A87373CB40897424453D863A8"
  target="_blank">G. Sher. <em>Logical Consequence</em>. Elements in Philosophy and Logic. Cambridge
University Press, 2022.</a></li>
</ul>
<p>Early work on AI implementations of inductive reasoning:</p>
<ul>
<li><i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://doi.org/10.1016/0004-3702%2880%2990011-9"
  target="_blank">J. McCarthy. &ldquo;Circumscription: A form of non-monotonic reasoning”, <em>Artificial
Intelligence</em>, 13: 27–39.</a></li>
</ul>
<p>The idea of using probability theory to model inductive validity is heavily
influenced by the work of Rudolf Carnap:</p>
<ul>
<li><i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://doi.org/10.1086/286851"
  target="_blank">R. Carnap. &ldquo;On inductive logic&rdquo;, <em>Philosophy of Science</em> 12(2):
72-97.</a></li>
</ul>
<p>Influential mathematical treatment of inductive validity:</p>
<ul>
<li><i class="bi bi-box-arrow-up-right h-6"></i>
<a class="link-dark" href="https://doi.org/10.1016/0004-3702%2890%2990101-5"
  target="_blank">S. Kraus, D. Lehmann, &amp; M. Magidor. &ldquo;Nonmonotonic Reasoning, Preferential
Models and Cumulative Logics&rdquo;. <em>Artifical Intelligence</em>, 44: 167–207,
1990.</a>.</li>
</ul>


  </div>
   <p><em>Last edited: </em>12/09/2025</p>
</div>


<ul class="navbar-nav flex-row justify-content-between mt-auto">
  
  <li class="nav-item">
    <a href="/textbook/formal-languages/" class="btn" tabindex="-1" role="button" aria-disabled="true">
      <i class="bi bi-chevron-left"></i>
    </a>
    
  </li>
  <li class="nav-item">
    <button class="btn btn-back-to-top">
    <i class="bi bi-chevron-double-up"></i>
  </button>
  </li>
  <li class="nav-item">
    
    <a href="/textbook/boolean/" class="btn" tabindex="-1" role="button" aria-disabled="true">
      <i class="bi bi-chevron-right"></i>
    </a>
    
  </li>
</ul>

    </main>
    <footer class="align-self-center d-flex flex-column mt-md-1 p-0" data-bs-theme="dark">
      <nav class="navbar bg-dark shadow" data-bs-theme="dark" aria-label="footer-navbar">
  <div class="container-sm align-self-center px-3">
    <a class="navbar-brand fs-6" href="/about" aria-label="copyright-link">&copy; 2025 jkorbmacher et al. </a>
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link fs-6" href="https://github.com/jkorb/logicalmethods.ai" target="_blank"><i class="bi bi-github"></i></a>
      </li>
    </ul>
  </div>
</nav>
 
      <script src="https://logicalmethods.ai/js/helpers.js"></script>
      <script src="https://logicalmethods.ai/bootstrap/dist/js/bootstrap.bundle.min.js"></script>
      
      
      
    </footer>
  </body>
</html>
